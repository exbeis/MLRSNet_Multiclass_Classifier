{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "torch.manual_seed(10)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Using {device} for inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get Dataset ###\n",
    "PATH = 'MLRSNet Dataset\\\\MLRSNet for Semantic Scene Understanding\\\\Images' #TODO Change if Necessary\n",
    "transform = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor()])\n",
    "#Normalization is included as part of ENetB2\n",
    "\n",
    "raw_dataset = torchvision.datasets.ImageFolder(PATH, transform=transform)\n",
    "\n",
    "### Get Indices ###\n",
    "NUM_CLASSES = 23 #TODO Change if needed\n",
    "NUM_DATAPOINTS = 7000 #TODO Change if needed\n",
    "num_each_class = int(np.ceil(NUM_DATAPOINTS / NUM_CLASSES))\n",
    "start_points = [0]\n",
    "for folder in os.listdir(PATH):\n",
    "    # print(len(os.listdir(PATH+ f\"\\\\{folder}\")))\n",
    "    next = start_points[-1] + len(os.listdir(PATH+f\"\\\\{folder}\"))\n",
    "    start_points.append(next)\n",
    "start_points.pop()\n",
    "indices = []\n",
    "for start in start_points:\n",
    "    next_class_indices = list(range(start,start+num_each_class))\n",
    "    indices = indices + next_class_indices\n",
    "# print(len(indices))\n",
    "\n",
    "### Get Subset of Dataset ###\n",
    "# raw_subset = torch.utils.data.Subset(raw_dataset, np.arange(num_datapoints)) #This line is wrong - only gets 2 to 3 classes in\n",
    "# raw_subset = torch.utils.data.Subset(raw_dataset, np.random.choice(len(raw_dataset), NUM_DATAPOINTS, replace=False))\n",
    "raw_subset = torch.utils.data.Subset(raw_dataset, indices)\n",
    "\n",
    "\n",
    "############## Code to take the images in order, so the ultimate test is on types of images never before seen in the train ################\n",
    "# n = len(raw_dataset)\n",
    "# n_train = int(0.6*n)\n",
    "# n_val = int(0.8*n)\n",
    "# train_dataset = torch.utils.data.Subset(raw_dataset, range(n_train))\n",
    "# val_dataset = torch.utils.data.Subset(raw_dataset, range(n_train, n_val))\n",
    "# test_dataset = torch.utils.data.Subset(raw_dataset, range(n_val, n+1))\n",
    "# print(\"No. Images in train, val, test\", len(train_dataset), len(val_dataset), len(test_dataset))\n",
    "\n",
    "\n",
    "### Get Train/Val/Test Splits ###\n",
    "n = len(raw_subset)\n",
    "n_train = int(0.6*n)\n",
    "n_val = int(0.2*n)\n",
    "n_test = int(0.2*n)\n",
    "leftover = n-n_train-n_test-n_val\n",
    "n_test += leftover\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(raw_subset, [n_train, n_val, n_test])\n",
    "# print(\"No. Images in train, val, test\", len(train_dataset), len(val_dataset), len(test_dataset))\n",
    "\n",
    "### Get Data Loaders ###\n",
    "LOADERS_BATCH_SIZE = 25 #AP #TODO Change if needed\n",
    "LOADERS_NUM_WORKERS = 2 #AP #TODO Change if needed\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=LOADERS_BATCH_SIZE, num_workers=LOADERS_NUM_WORKERS, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=LOADERS_BATCH_SIZE, num_workers=LOADERS_NUM_WORKERS, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=LOADERS_BATCH_SIZE, num_workers=LOADERS_NUM_WORKERS, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
